{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\r\n",
      "  Downloading timm-1.0.15-py3-none-any.whl.metadata (52 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m52.0/52.0 kB\u001B[0m \u001B[31m721.2 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: torch in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from timm) (2.3.0)\r\n",
      "Requirement already satisfied: torchvision in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from timm) (0.18.0)\r\n",
      "Requirement already satisfied: pyyaml in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from timm) (6.0.1)\r\n",
      "Collecting huggingface_hub (from timm)\r\n",
      "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\r\n",
      "Collecting safetensors (from timm)\r\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: filelock in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from huggingface_hub->timm) (3.14.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.5.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from huggingface_hub->timm) (24.0)\r\n",
      "Requirement already satisfied: requests in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from huggingface_hub->timm) (2.32.1)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from huggingface_hub->timm) (4.11.0)\r\n",
      "Requirement already satisfied: sympy in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from torch->timm) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from torch->timm) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from torch->timm) (3.1.4)\r\n",
      "Requirement already satisfied: numpy in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from torchvision->timm) (10.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\r\n",
      "Downloading timm-1.0.15-py3-none-any.whl (2.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m9.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m468.0/468.0 kB\u001B[0m \u001B[31m18.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading safetensors-0.5.2-cp38-abi3-macosx_11_0_arm64.whl (408 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m408.9/408.9 kB\u001B[0m \u001B[31m20.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: safetensors, huggingface_hub, timm\r\n",
      "Successfully installed huggingface_hub-0.29.1 safetensors-0.5.2 timm-1.0.15\r\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-23T19:17:26.434493Z",
     "start_time": "2025-02-23T19:17:21.911222Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-23T19:24:38.811554Z",
     "start_time": "2025-02-23T19:24:37.164194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import timm  # Make sure timm is installed: pip install timm\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# =======================\n",
    "# 1. Data Preparation\n",
    "# =======================\n",
    "# CIFAR-10 dataset; note that we resize images to 224x224 because most pre-trained models (e.g. DINOv2) expect larger inputs.\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Using ImageNet normalization\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/rkovalch/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "data": {
      "text/plain": "Linear(in_features=768, out_features=10, bias=True)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =======================\n",
    "# 2. Model Setup\n",
    "# =======================\n",
    "feature_extractor = torch.hub.load('facebookresearch/dinov2', \"dinov2_vitb14\")\n",
    "# No need to call reset_classifier; the head is already Identity.\n",
    "feature_extractor.eval()\n",
    "\n",
    "# Freeze the backbone parameters\n",
    "for param in feature_extractor.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Determine the feature dimension (e.g. 768 for ViT-B/14)\n",
    "num_features = 768\n",
    "num_classes = 10  # CIFAR-10 has 10 classes\n",
    "\n",
    "# Create a linear classifier on top of the frozen features.\n",
    "linear_classifier = nn.Linear(num_features, num_classes)\n",
    "linear_classifier.to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-23T19:24:41.438460Z",
     "start_time": "2025-02-23T19:24:39.004963Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 3. Training Setup\n",
    "# =======================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(linear_classifier.parameters(), lr=0.01, momentum=0.9)\n",
    "num_epochs = 10\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-23T19:24:41.441926Z",
     "start_time": "2025-02-23T19:24:41.440359Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epochs progress:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "train loader:   0%|          | 0/782 [00:00<?, ?it/s]\u001B[A\n",
      "train loader:   0%|          | 1/782 [00:07<1:38:39,  7.58s/it]\u001B[A\n",
      "train loader:   0%|          | 2/782 [00:11<1:09:34,  5.35s/it]\u001B[A\n",
      "train loader:   0%|          | 3/782 [00:15<1:00:09,  4.63s/it]\u001B[A\n",
      "train loader:   1%|          | 4/782 [00:18<55:53,  4.31s/it]  \u001B[A\n",
      "train loader:   1%|          | 5/782 [00:22<53:31,  4.13s/it]\u001B[A\n",
      "train loader:   1%|          | 6/782 [00:26<52:00,  4.02s/it]\u001B[A\n",
      "train loader:   1%|          | 7/782 [00:30<50:58,  3.95s/it]\u001B[A\n",
      "train loader:   1%|          | 8/782 [00:34<50:09,  3.89s/it]\u001B[A\n",
      "train loader:   1%|          | 9/782 [00:37<49:40,  3.86s/it]\u001B[A\n",
      "train loader:   1%|▏         | 10/782 [00:41<49:15,  3.83s/it]\u001B[A\n",
      "train loader:   1%|▏         | 11/782 [00:45<49:08,  3.82s/it]\u001B[A\n",
      "train loader:   2%|▏         | 12/782 [00:49<49:02,  3.82s/it]\u001B[A\n",
      "train loader:   2%|▏         | 13/782 [00:53<48:51,  3.81s/it]\u001B[A\n",
      "train loader:   2%|▏         | 14/782 [00:56<48:40,  3.80s/it]\u001B[A\n",
      "train loader:   2%|▏         | 15/782 [01:00<48:53,  3.82s/it]\u001B[A\n",
      "train loader:   2%|▏         | 16/782 [01:04<48:45,  3.82s/it]\u001B[A\n",
      "train loader:   2%|▏         | 17/782 [01:08<48:35,  3.81s/it]\u001B[A\n",
      "train loader:   2%|▏         | 18/782 [01:12<50:54,  4.00s/it]\u001B[A\n",
      "train loader:   2%|▏         | 19/782 [01:16<50:47,  3.99s/it]\u001B[A\n",
      "train loader:   3%|▎         | 20/782 [01:20<50:44,  4.00s/it]\u001B[A\n",
      "train loader:   3%|▎         | 21/782 [01:24<50:44,  4.00s/it]\u001B[A\n",
      "train loader:   3%|▎         | 22/782 [01:28<50:28,  3.99s/it]\u001B[A\n",
      "train loader:   3%|▎         | 23/782 [01:32<50:37,  4.00s/it]\u001B[A\n",
      "train loader:   3%|▎         | 24/782 [01:36<50:22,  3.99s/it]\u001B[A\n",
      "train loader:   3%|▎         | 25/782 [01:40<50:04,  3.97s/it]\u001B[A\n",
      "train loader:   3%|▎         | 26/782 [01:44<49:51,  3.96s/it]\u001B[A\n",
      "train loader:   3%|▎         | 27/782 [01:48<48:51,  3.88s/it]\u001B[A\n",
      "train loader:   4%|▎         | 28/782 [01:52<48:17,  3.84s/it]\u001B[A\n",
      "train loader:   4%|▎         | 29/782 [01:55<47:35,  3.79s/it]\u001B[A\n",
      "train loader:   4%|▍         | 30/782 [01:59<47:10,  3.76s/it]\u001B[A\n",
      "train loader:   4%|▍         | 31/782 [02:03<47:01,  3.76s/it]\u001B[A\n",
      "train loader:   4%|▍         | 32/782 [02:07<47:33,  3.81s/it]\u001B[A\n",
      "train loader:   4%|▍         | 33/782 [02:10<47:24,  3.80s/it]\u001B[A\n",
      "train loader:   4%|▍         | 34/782 [02:14<47:01,  3.77s/it]\u001B[A\n",
      "train loader:   4%|▍         | 35/782 [02:18<46:43,  3.75s/it]\u001B[A\n",
      "train loader:   5%|▍         | 36/782 [02:22<46:29,  3.74s/it]\u001B[A\n",
      "train loader:   5%|▍         | 37/782 [02:25<46:18,  3.73s/it]\u001B[A\n",
      "train loader:   5%|▍         | 38/782 [02:29<46:08,  3.72s/it]\u001B[A\n",
      "train loader:   5%|▍         | 39/782 [02:33<46:00,  3.72s/it]\u001B[A\n",
      "train loader:   5%|▌         | 40/782 [02:36<46:00,  3.72s/it]\u001B[A\n",
      "train loader:   5%|▌         | 41/782 [02:40<45:57,  3.72s/it]\u001B[A\n",
      "train loader:   5%|▌         | 42/782 [02:44<45:50,  3.72s/it]\u001B[A\n",
      "train loader:   5%|▌         | 43/782 [02:47<45:45,  3.71s/it]\u001B[A\n",
      "train loader:   6%|▌         | 44/782 [02:51<45:35,  3.71s/it]\u001B[A\n",
      "train loader:   6%|▌         | 45/782 [02:55<45:30,  3.70s/it]\u001B[A\n",
      "train loader:   6%|▌         | 46/782 [02:59<45:28,  3.71s/it]\u001B[A\n",
      "train loader:   6%|▌         | 47/782 [03:02<45:29,  3.71s/it]\u001B[A\n",
      "train loader:   6%|▌         | 48/782 [03:06<45:29,  3.72s/it]\u001B[A\n",
      "train loader:   6%|▋         | 49/782 [03:10<45:24,  3.72s/it]\u001B[A\n",
      "train loader:   6%|▋         | 50/782 [03:13<45:26,  3.72s/it]\u001B[A\n",
      "train loader:   7%|▋         | 51/782 [03:17<45:19,  3.72s/it]\u001B[A\n",
      "train loader:   7%|▋         | 52/782 [03:21<45:15,  3.72s/it]\u001B[A\n",
      "train loader:   7%|▋         | 53/782 [03:25<45:08,  3.72s/it]\u001B[A\n",
      "train loader:   7%|▋         | 54/782 [03:28<45:01,  3.71s/it]\u001B[A\n",
      "train loader:   7%|▋         | 55/782 [03:32<44:52,  3.70s/it]\u001B[A\n",
      "train loader:   7%|▋         | 56/782 [03:36<44:44,  3.70s/it]\u001B[A\n",
      "train loader:   7%|▋         | 57/782 [03:39<44:45,  3.70s/it]\u001B[A\n",
      "train loader:   7%|▋         | 58/782 [03:43<44:43,  3.71s/it]\u001B[A\n",
      "train loader:   8%|▊         | 59/782 [03:47<44:40,  3.71s/it]\u001B[A\n",
      "train loader:   8%|▊         | 60/782 [03:51<44:49,  3.72s/it]\u001B[A\n",
      "train loader:   8%|▊         | 61/782 [03:54<44:42,  3.72s/it]\u001B[A\n",
      "train loader:   8%|▊         | 62/782 [03:58<44:37,  3.72s/it]\u001B[A\n",
      "train loader:   8%|▊         | 63/782 [04:02<44:29,  3.71s/it]\u001B[A\n",
      "train loader:   8%|▊         | 64/782 [04:05<44:31,  3.72s/it]\u001B[A\n",
      "train loader:   8%|▊         | 65/782 [04:09<44:25,  3.72s/it]\u001B[A\n",
      "train loader:   8%|▊         | 66/782 [04:13<44:19,  3.71s/it]\u001B[A\n",
      "train loader:   9%|▊         | 67/782 [04:17<44:14,  3.71s/it]\u001B[A\n",
      "train loader:   9%|▊         | 68/782 [04:20<44:08,  3.71s/it]\u001B[A\n",
      "train loader:   9%|▉         | 69/782 [04:24<44:08,  3.71s/it]\u001B[A\n",
      "train loader:   9%|▉         | 70/782 [04:28<44:02,  3.71s/it]\u001B[A\n",
      "train loader:   9%|▉         | 71/782 [04:31<44:02,  3.72s/it]\u001B[A\n",
      "train loader:   9%|▉         | 72/782 [04:35<43:46,  3.70s/it]\u001B[A\n",
      "train loader:   9%|▉         | 73/782 [04:39<43:39,  3.69s/it]\u001B[A\n",
      "train loader:   9%|▉         | 74/782 [04:43<44:00,  3.73s/it]\u001B[A\n",
      "train loader:  10%|▉         | 75/782 [04:47<44:36,  3.79s/it]\u001B[A\n",
      "train loader:  10%|▉         | 76/782 [04:50<44:56,  3.82s/it]\u001B[A\n",
      "train loader:  10%|▉         | 77/782 [04:54<44:31,  3.79s/it]\u001B[A\n",
      "train loader:  10%|▉         | 78/782 [04:58<44:03,  3.75s/it]\u001B[A\n",
      "train loader:  10%|█         | 79/782 [05:02<46:31,  3.97s/it]\u001B[A\n",
      "train loader:  10%|█         | 80/782 [05:07<47:32,  4.06s/it]\u001B[A\n",
      "train loader:  10%|█         | 81/782 [05:11<47:33,  4.07s/it]\u001B[A\n",
      "train loader:  10%|█         | 82/782 [05:15<47:04,  4.03s/it]\u001B[A\n",
      "train loader:  11%|█         | 83/782 [05:19<48:09,  4.13s/it]\u001B[A\n",
      "train loader:  11%|█         | 84/782 [05:23<47:25,  4.08s/it]\u001B[AException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x117392950>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/rkovalch/miniconda3/envs/cv-env/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "train loader:  11%|█         | 84/782 [05:25<45:08,  3.88s/it]\n",
      "epochs progress:   0%|          | 0/10 [05:25<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Extract features using the frozen DINOv2 backbone.\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 17\u001B[0m     features_dict \u001B[38;5;241m=\u001B[39m \u001B[43mfeature_extractor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;66;03m# Extract the class token from the returned dictionary.\u001B[39;00m\n\u001B[1;32m     19\u001B[0m     features \u001B[38;5;241m=\u001B[39m features_dict[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_norm_clstoken\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py:261\u001B[0m, in \u001B[0;36mDinoVisionTransformer.forward_features\u001B[0;34m(self, x, masks)\u001B[0m\n\u001B[1;32m    258\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_tokens_with_masks(x, masks)\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m blk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks:\n\u001B[0;32m--> 261\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mblk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    263\u001B[0m x_norm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm(x)\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m    265\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_norm_clstoken\u001B[39m\u001B[38;5;124m\"\u001B[39m: x_norm[:, \u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    266\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx_norm_regtokens\u001B[39m\u001B[38;5;124m\"\u001B[39m: x_norm[:, \u001B[38;5;241m1\u001B[39m : \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_register_tokens \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    269\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmasks\u001B[39m\u001B[38;5;124m\"\u001B[39m: masks,\n\u001B[1;32m    270\u001B[0m }\n",
      "File \u001B[0;32m~/miniconda3/envs/cv-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/cv-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:254\u001B[0m, in \u001B[0;36mNestedTensorBlock.forward\u001B[0;34m(self, x_or_x_list)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x_or_x_list):\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x_or_x_list, Tensor):\n\u001B[0;32m--> 254\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_or_x_list\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    255\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x_or_x_list, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    256\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m XFORMERS_AVAILABLE:\n",
      "File \u001B[0;32m~/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:112\u001B[0m, in \u001B[0;36mBlock.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    110\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdrop_path1(ffn_residual_func(x))  \u001B[38;5;66;03m# FIXME: drop_path2\u001B[39;00m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 112\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[43mattn_residual_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    113\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m ffn_residual_func(x)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:91\u001B[0m, in \u001B[0;36mBlock.forward.<locals>.attn_residual_func\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mattn_residual_func\u001B[39m(x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m---> 91\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mls1(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattn(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m))\n",
      "File \u001B[0;32m~/miniconda3/envs/cv-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/cv-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/cv-env/lib/python3.10/site-packages/torch/nn/modules/normalization.py:201\u001B[0m, in \u001B[0;36mLayerNorm.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    200\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 201\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalized_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/cv-env/lib/python3.10/site-packages/torch/nn/functional.py:2573\u001B[0m, in \u001B[0;36mlayer_norm\u001B[0;34m(input, normalized_shape, weight, bias, eps)\u001B[0m\n\u001B[1;32m   2569\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_variadic(\u001B[38;5;28minput\u001B[39m, weight, bias):\n\u001B[1;32m   2570\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m   2571\u001B[0m         layer_norm, (\u001B[38;5;28minput\u001B[39m, weight, bias), \u001B[38;5;28minput\u001B[39m, normalized_shape, weight\u001B[38;5;241m=\u001B[39mweight, bias\u001B[38;5;241m=\u001B[39mbias, eps\u001B[38;5;241m=\u001B[39meps\n\u001B[1;32m   2572\u001B[0m     )\n\u001B[0;32m-> 2573\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer_norm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalized_shape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackends\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcudnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menabled\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 4. Training Loop (Linear Probe)\n",
    "# =======================\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"epochs progress\"):\n",
    "    linear_classifier.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=\"train loader\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Extract features using the frozen DINOv2 backbone.\n",
    "        with torch.no_grad():\n",
    "            features_dict = feature_extractor.forward_features(inputs)\n",
    "            # Extract the class token from the returned dictionary.\n",
    "            features = features_dict[\"x_norm_clstoken\"]\n",
    "            # Optionally, if your model returns a 4D tensor and you want to average pool patch tokens,\n",
    "            # you could modify accordingly, e.g.:\n",
    "            # features = features_dict[\"x_norm_patchtokens\"]\n",
    "            # features = features.mean(dim=[2, 3])\n",
    "\n",
    "        # Forward pass through the linear classifier.\n",
    "        outputs = linear_classifier(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total * 100\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-23T19:33:26.857192Z",
     "start_time": "2025-02-23T19:28:00.700860Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
